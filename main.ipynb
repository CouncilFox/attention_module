{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load VGG16 with Pretrained Weights\n",
    "First, we'll load the VGG16 model with weights pretrained on ImageNet. We'll include the classification top since we aim to classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTypeError: <class 'traitlets.traitlets.List'> is not a generic class. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Load the VGG16 model with pretrained weights and include the top classification layers\n",
    "vgg16 = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "\n",
    "Model Loading: By setting weights='imagenet', we ensure the model is initialized with weights trained on the ImageNet dataset.\n",
    "Include Top Layers: include_top=True includes the fully connected layers at the top of the network, which are necessary for classification tasks.\n",
    "Input Shape: The default input shape for VGG16 is (224, 224, 3), matching the ImageNet images.\n",
    "\n",
    "\n",
    "## VGG16 Layer Naming:\n",
    "\n",
    "We'll refer to the layers as specified:\n",
    "\n",
    "Convolutional Layers: conv 1-1, conv 1-2, ..., conv 5-3\n",
    "Pooling Layers: pooling layers after each block\n",
    "Dense Layers: Three dense layers at the top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implement the CBAM Attention Module\n",
    "We choose to implement the Convolutional Block Attention Module (CBAM) because it combines both channel and spatial attention, potentially offering better performance.\n",
    "\n",
    "CBAM Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Layer,\n",
    "    GlobalAveragePooling2D,\n",
    "    GlobalMaxPooling2D,\n",
    "    Dense,\n",
    "    Multiply,\n",
    "    Conv2D,\n",
    "    Add,\n",
    "    Activation,\n",
    "    Reshape,\n",
    ")\n",
    "\n",
    "\n",
    "def cbam_module(input_feature, reduction_ratio=16):\n",
    "    \"\"\"Convolutional Block Attention Module (CBAM)\"\"\"\n",
    "    # Channel Attention Module\n",
    "    channel = input_feature.shape[-1]\n",
    "    shared_layer_one = Dense(channel // reduction_ratio, activation=\"relu\")\n",
    "    shared_layer_two = Dense(channel)\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = Reshape((1, 1, channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = Reshape((1, 1, channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    channel_attention = Add()([avg_pool, max_pool])\n",
    "    channel_attention = Activation(\"sigmoid\")(channel_attention)\n",
    "    channel_refined = Multiply()([input_feature, channel_attention])\n",
    "\n",
    "    # Spatial Attention Module\n",
    "    avg_pool_spatial = tf.reduce_mean(channel_refined, axis=-1, keepdims=True)\n",
    "    max_pool_spatial = tf.reduce_max(channel_refined, axis=-1, keepdims=True)\n",
    "    spatial_attention = tf.concat([avg_pool_spatial, max_pool_spatial], axis=-1)\n",
    "    spatial_attention = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(\n",
    "        spatial_attention\n",
    "    )\n",
    "    spatial_refined = Multiply()([channel_refined, spatial_attention])\n",
    "\n",
    "    return spatial_refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
